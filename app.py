import streamlit as st
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
import altair as alt
import openai

# â”€â”€ 1) PAGE CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="Instagram Reels Performance Dashboard", layout="wide")
st.title("ğŸ“Š Instagram Reels Performance Dashboard")

# â”€â”€ 2) LOAD & CLEAN FULL DATA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df_full = pd.read_csv("posts_zero1byzerodha.csv")
df_full.columns = df_full.columns.str.strip().str.lower()
if 'type' in df_full.columns:
    df_full = df_full[df_full['type'].str.lower() == 'reel']

for col in ['reach','shares','saved','comments','likes']:
    if col in df_full.columns:
        df_full[col] = (
            df_full[col].astype(str)
                   .str.replace(r'[^\d.]','', regex=True)
                   .replace('', np.nan)
                   .astype(float)
        )

# â”€â”€ 3) TRAIN & CATEGORIZE ON FULL DATA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
features = [c for c in ['shares','saved','comments','likes'] if c in df_full.columns]
X_full = df_full[features].fillna(0)
y_full = df_full['reach'].fillna(0)
full_model = LinearRegression().fit(X_full, y_full)
df_full['predicted_reach'] = full_model.predict(X_full)

def categorize_ratio(a, p):
    if p <= 0:      return 'Poor'
    r = a/p
    if r > 2.0:     return 'Viral'
    if r > 1.5:     return 'Excellent'
    if r > 1.0:     return 'Good'
    if r > 0.5:     return 'Average'
    return 'Poor'

df_full['performance'] = df_full.apply(
    lambda r: categorize_ratio(r['reach'], r['predicted_reach']), axis=1
)

# â”€â”€ 4) ONE-TIME CORRELATIONS BY CATEGORY (FULL DATA) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cats = ['Viral','Excellent','Good','Average','Poor']
corr_by_cat = pd.DataFrame(index=features, columns=cats)
df_no = df_full.copy()
for f in features + ['reach']:
    lo, hi = df_no[f].quantile([0.01, 0.99])
    df_no = df_no[df_no[f].between(lo, hi)]

for cat in cats:
    sub = df_no[df_no['performance'] == cat]
    if len(sub) >= 3:  # require â‰¥3 for stable correlation
        corr_by_cat[cat] = sub[features + ['reach']].corr().loc['reach', features]
    else:
        corr_by_cat[cat] = np.nan

# â”€â”€ 5) COPY FOR FILTERING & FILTERED MODEL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df = df_full.copy()

# â”€â”€ 6) DATE FILTER IN SIDEBAR â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
date_col = next((c for c in df.columns if 'date' in c), None)
if date_col:
    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
    df.dropna(subset=[date_col], inplace=True)
    df['post_date']    = df[date_col].dt.date
    df['post_date_dt'] = pd.to_datetime(df['post_date'])
    st.sidebar.subheader("ğŸ“… Filter by Post Date")
    start_date, end_date = st.sidebar.date_input(
        "Select date range",
        [df['post_date'].min(), df['post_date'].max()]
    )
    df = df[df['post_date'].between(start_date, end_date)]
else:
    st.sidebar.info("No date column found for filtering.")

# â”€â”€ 7) RETRAIN REGRESSION ON FILTERED DATA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
X = df[features].fillna(0)
y = df['reach'].fillna(0)
model = LinearRegression().fit(X, y)
df['predicted_reach'] = model.predict(X)

# â”€â”€ 8) RATIO-BASED CATEGORIZATION FOR FILTERED DATA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df['performance'] = df.apply(
    lambda r: categorize_ratio(r['reach'], r['predicted_reach']), axis=1
)

# â”€â”€ 9) NUMBER FORMATTING HELPER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fmt(n):
    if pd.isna(n):      return "-"
    if n >= 1e6:        return f"{n/1e6:.2f}M"
    if n >= 1e3:        return f"{n/1e3:.1f}K"
    return str(int(n))

# â”€â”€ 10) SUMMARY INSIGHTS: ALL POSTS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ“ˆ Summary Insights (All Categories Totals)")
total_act_all = df['reach'].sum()
total_pred_all = df['predicted_reach'].sum()
err_pct_all = (abs(total_act_all - total_pred_all) / total_pred_all * 100) if total_pred_all else 0
c1, c2, c3 = st.columns(3)
c1.metric("Total Actual Reach",    fmt(total_act_all))
c2.metric("Total Predicted Reach", fmt(total_pred_all))
c3.metric("Mean % Error",          f"{err_pct_all:.2f}%")

# â”€â”€ 11) SUMMARY INSIGHTS: VIRAL & EXCELLENT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ“ˆ Summary Insights (Viral & Excellent Totals)")
ve = df[df['performance'].isin(['Viral','Excellent'])]
total_act_ve = ve['reach'].sum()
total_pred_ve = ve['predicted_reach'].sum()
err_pct_ve = (abs(total_act_ve - total_pred_ve) / total_pred_ve * 100) if total_pred_ve else 0
c4, c5, c6 = st.columns(3)
c4.metric("Total Actual Reach",    fmt(total_act_ve))
c5.metric("Total Predicted Reach", fmt(total_pred_ve))
c6.metric("Mean % Error",          f"{err_pct_ve:.2f}%")

# â”€â”€ 12) VIRAL & EXCELLENT REELS TABLE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ”¥ Viral & Excellent Reels")
if not ve.empty:
    table = ve[['post_date','caption'] + features + ['reach','predicted_reach','performance']].copy()
    table['reach']           = table['reach'].apply(fmt)
    table['predicted_reach'] = table['predicted_reach'].apply(fmt)
    table = table.rename(columns={
        'post_date':'Date','caption':'Caption',
        'shares':'Shares','saved':'Saves','comments':'Comments','likes':'Likes',
        'reach':'Reach','predicted_reach':'Predicted Reach','performance':'Performance'
    })
    st.dataframe(
        table.style.set_properties(subset=['Caption'], **{'white-space':'pre-wrap'}),
        use_container_width=True
    )
else:
    st.write("No Viral/Excellent reels in this date range.")

# â”€â”€ 13) PERFORMANCE DISTRIBUTION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ“Š Performance Distribution")
dist = df['performance'].value_counts().reindex(cats, fill_value=0)
st.bar_chart(dist)

# â”€â”€ 14) REACH TREND OVER TIME â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ“ˆ Reach Trend Over Time")
if 'post_date_dt' in df.columns and not df.empty:
    ts = df.set_index('post_date_dt')[['reach','predicted_reach']].rename(
        columns={'reach':'Actual Reach','predicted_reach':'Predicted Reach'}
    )
    st.line_chart(ts)
else:
    st.write("No date-indexed data to plot trend.")

# â”€â”€ 15) ENGAGEMENT CORRELATIONS BY CATEGORY (FULL DATA) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ”— Engagement Correlations by Category (full data)")
corr_src = (
    corr_by_cat
      .reset_index()
      .melt('index', var_name='Category', value_name='Correlation')
      .rename(columns={'index':'Engagement'})
)
chart = (
    alt.Chart(corr_src)
       .mark_bar()
       .encode(
           x=alt.X('Engagement:N', title='Engagement Metric'),
           xOffset='Category:N',
           y='Correlation:Q',
           color='Category:N'
       )
       .properties(width='container', height=300)
)
st.altair_chart(chart, use_container_width=True)

# â”€â”€ 16) CONTENT INTELLIGENCE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ§  Content Intelligence")
api_key = st.secrets.get("OPENAI_API_KEY") or st.secrets.get("general",{}).get("OPENAI_API_KEY")
if api_key and 'caption' in df_full.columns:
    client = openai.OpenAI(api_key=api_key)
    sample = df_full['caption'].dropna().astype(str).sample(min(5, len(df_full))).tolist()
    prompt = (
        "You are an Instagram strategist. Based on these 5 reel captions:\n\n"
        + "\n".join(f"- {t}" for t in sample)
        + "\n\nGive:\n"
          "1. Common content patterns or themes\n"
          "2. Predicted tone or emotion\n"
          "3. One idea to improve virality\n"
    )
    try:
        resp = client.chat.completions.create(
            model="gpt-4",
            messages=[{"role":"user","content":prompt}]
        )
        st.markdown(resp.choices[0].message.content)
    except Exception as e:
        st.error(f"NLP error: {e}")
else:
    st.info("Add OPENAI_API_KEY to Streamlit secrets to enable Content Intelligence.")

# â”€â”€ 17) STRATEGIC TAKEAWAYS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸš€ Strategic Takeaways")
st.markdown("""
1. **Double-down on saveable â€œhow-toâ€ tips** â€“ high saves drive long-term reach.  
2. **Drive share prompts** (â€œtag a friendâ€) for algorithmic uplift.  
3. **Leverage trending audio** for extra boost.  
4. **Post Wed/Thu evenings (6â€“9 PM IST)** for peak engagement.  
5. **Collaborate** â€“ co-tags double your viral odds.  
6. **Optimize captions** with targeted hashtags + emojis.
""")

# â”€â”€ 18) DOWNLOAD & PREDICT & DIAGNOSE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("â¬‡ï¸ Download Full Data")
st.download_button(
    "Download CSV",
    df.to_csv(index=False).encode('utf-8'),
    "reels_with_predictions.csv",
    "text/csv"
)

st.subheader("ğŸ¯ Predict & Diagnose for a New Reel")
with st.form("diagnose_form"):
    s  = st.number_input("Shares",      0, value=0)
    sv = st.number_input("Saves",       0, value=0)
    c  = st.number_input("Comments",    0, value=0)
    l  = st.number_input("Likes",       0, value=0)
    ar = st.number_input("Actual Reach",0, value=0)
    go = st.form_submit_button("Diagnose")

if go:
    inp   = pd.DataFrame([{'shares':s,'saved':sv,'comments':c,'likes':l}])
    pred  = model.predict(inp)[0]
    perf  = categorize_ratio(ar, pred)

    st.success(f"ğŸ“¢ Predicted Reach: {fmt(pred)}")
    st.info(f"ğŸ” Actual Reach: {fmt(ar)}")
    st.info(f"ğŸ¯ Category: **{perf}**")

    st.markdown("**ğŸ“ˆ Engagement Correlations by Category (full data):**")
    st.table(corr_by_cat)

    promo = {'Poor':'Average','Average':'Good','Good':'Excellent','Excellent':'Viral'}
    if perf in promo:
        tgt  = promo[perf]
        rcat = corr_by_cat[tgt]
        if rcat.notna().any():
            best, val = rcat.idxmax(), rcat.max()
            st.markdown(
                f"ğŸ”œ To move **{perf}** â†’ **{tgt}**, focus on "
                f"**{best.capitalize()}** (r={val:.2f})."
            )
        else:
            st.write("ğŸ” Not enough data to recommend next steps.")
    else:
        st.markdown("âœ… Youâ€™re already in **Viral** territoryâ€”awesome work!")
