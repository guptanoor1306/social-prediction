import streamlit as st
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
import openai

# â”€â”€ Page config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="Instagram Reels Performance Dashboard", layout="wide")
st.title("ğŸ“Š Instagram Reels Performance Dashboard")

# â”€â”€ Load & preprocess data â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df = pd.read_csv("posts_zero1byzerodha.csv")
df.columns = df.columns.str.strip().str.lower()

# Keep only Reels
if 'type' in df.columns:
    df = df[df['type'].str.lower() == 'reel']

# Clean numeric fields
for col in ['reach','shares','saved','comments','likes']:
    if col in df.columns:
        df[col] = (
            df[col].astype(str)
                   .str.replace(r'[^\d.]','', regex=True)
                   .replace('', np.nan)
                   .astype(float)
        )

# â”€â”€ Date filter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
date_col = next((c for c in df.columns if 'date' in c), None)
if date_col:
    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
    df.dropna(subset=[date_col], inplace=True)
    df['post_date']    = df[date_col].dt.date
    df['post_date_dt'] = pd.to_datetime(df['post_date'])
    st.sidebar.subheader("ğŸ“… Filter by Post Date")
    sd, ed = st.sidebar.date_input(
        "Select date range",
        [df['post_date'].min(), df['post_date'].max()]
    )
    df = df[df['post_date'].between(sd, ed)]
else:
    st.sidebar.info("No date column found for filtering.")

# â”€â”€ Train & Predict (Linear Regression) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
features = [f for f in ['shares','saved','comments','likes'] if f in df.columns]
X = df[features].fillna(0)
y = df['reach'].fillna(0)
model = LinearRegression().fit(X, y)
df['predicted_reach'] = model.predict(X)

# â”€â”€ Remove superâ€outliers for correlation analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df_no = df.copy()
for f in features + ['reach']:
    if f in df_no.columns:
        low, high = df_no[f].quantile([0.01, 0.99])
        df_no = df_no[df_no[f].between(low, high)]

# â”€â”€ Compute correlations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
corr_overall = df_no[features + ['reach']].corr()['reach'].drop('reach').sort_values(ascending=False)

cats = ['Poor','Average','Good','Excellent','Viral']
corr_by_cat = pd.DataFrame(index=features, columns=cats)
for cat in cats:
    sub = df_no[df_no['performance'] == cat] if 'performance' in df_no.columns else pd.DataFrame()
    if len(sub) > len(features):
        corr_by_cat[cat] = sub[features + ['reach']].corr().loc['reach', features]
    else:
        corr_by_cat[cat] = np.nan

# â”€â”€ Categorize performance â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def categorize(actual, pred):
    if pred <= 0:
        return 'Poor'
    r = actual / pred
    if r > 2.0:    return 'Viral'
    if r > 1.5:    return 'Excellent'
    if r > 1.0:    return 'Good'
    if r > 0.5:    return 'Average'
    return 'Poor'

df['performance'] = df.apply(lambda r: categorize(r['reach'], r['predicted_reach']), axis=1)
ve = df[df['performance'].isin(['Viral','Excellent'])]

# â”€â”€ Formatting helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fmt(n):
    if pd.isna(n): return "-"
    if n >= 1e6:   return f"{n/1e6:.2f}M"
    if n >= 1e3:   return f"{n/1e3:.1f}K"
    return str(int(n))

# â”€â”€ Summary Metrics (Viral & Excellent Totals) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ“ˆ Summary Insights (Viral & Excellent Totals)")
c1, c2, c3 = st.columns(3)
ta = ve['reach'].sum()
tp = ve['predicted_reach'].sum()
dev = (abs(ta - tp) / tp * 100) if tp else 0

c1.metric("Total Actual Reach",    fmt(ta))
c2.metric("Total Predicted Reach", fmt(tp))
c3.metric("Deviation %",           f"{dev:.2f}%")

with st.expander("ğŸ§  Why is the deviation high?"):
    st.markdown("- Collaborative or outlier posts skew totals.")
    st.markdown("- Linear model may under/over estimate extreme cases.")
    st.markdown("- Summary limited to Viral & Excellent posts.")

# â”€â”€ Viral & Excellent Reels Table â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ”¥ Viral & Excellent Reels")
if not ve.empty:
    out = ve.copy()
    cols = ['post_date','caption'] + features + ['reach','predicted_reach','performance']
    out = out[[c for c in cols if c in out.columns]]
    out['reach']           = out['reach'].apply(fmt)
    out['predicted_reach'] = out['predicted_reach'].apply(fmt)
    out = out.rename(columns={
        'post_date':'Date','caption':'Caption',
        'shares':'Shares','saved':'Saves','comments':'Comments','likes':'Likes',
        'reach':'Reach','predicted_reach':'Predicted Reach','performance':'Performance'
    })
    st.dataframe(
        out.style.set_properties(subset=['Caption'], **{'white-space':'pre-wrap'}),
        use_container_width=True
    )
else:
    st.write("No Viral & Excellent reels in this range.")

# â”€â”€ Performance Distribution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ“Š Performance Distribution")
perf_counts = df['performance'].value_counts().reindex(cats, fill_value=0)
st.bar_chart(perf_counts)

# â”€â”€ Reach Trend Over Time â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ“ˆ Reach Trend Over Time")
if 'post_date_dt' in df.columns:
    weekly = (df.set_index('post_date_dt')
                .resample('W')[['reach','predicted_reach']]
                .mean()
                .rename(columns={'reach':'Actual Reach','predicted_reach':'Predicted Reach'}))
    st.line_chart(weekly)

# â”€â”€ Engagement Correlation by Category â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ”— Engagement Correlation by Category")
st.bar_chart(corr_by_cat)

# â”€â”€ Intelligent Insights â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ’¡ Intelligent Insights")
if 'post_date_dt' in df.columns:
    df['weekday'] = df['post_date_dt'].dt.day_name()
    avg_day = df.groupby('weekday')['reach'].mean().reindex(
        ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']
    ).dropna()
    st.bar_chart(avg_day)
    best_day = avg_day.idxmax()
    st.markdown(f"- ğŸ“… Highest average reach on **{best_day}** ({fmt(avg_day.max())}).")
q1, q2, q3 = df['reach'].quantile([0.25,0.5,0.75])
st.markdown(f"- ğŸ“Š Reach quartiles: 25% < {fmt(q1)}, median {fmt(q2)}, 75% > {fmt(q3)}.")

# â”€â”€ Content Intelligence (NLP) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ§  Content Intelligence (NLP)")
api_key = st.secrets.get("OPENAI_API_KEY") or st.secrets.get("general",{}).get("OPENAI_API_KEY")
if api_key and any(c in df.columns for c in ['caption','title']):
    client = openai.OpenAI(api_key=api_key)
    tc = 'caption' if 'caption' in df.columns else 'title'
    texts = df[tc].dropna().astype(str)
    if not texts.empty:
        sample = texts.sample(min(5,len(texts))).tolist()
        prompt = (f"You are an Instagram strategist. Analyze these {tc}s for patterns, themes, and tone:\n"
                  + "\n".join(sample))
        try:
            resp = client.chat.completions.create(
                model="gpt-4", messages=[{"role":"user","content":prompt}]
            )
            st.markdown(resp.choices[0].message.content)
        except Exception as e:
            st.error(f"NLP error: {e}")
else:
    st.warning("Add OPENAI_API_KEY to secrets and include a caption/title column for NLP.")

# â”€â”€ Top 5 by Virality Score â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸ“ˆ Top Content by Virality Score")
df['virality_score'] = df['reach'] / np.where(df['predicted_reach']==0, np.nan, df['predicted_reach'])
df['virality_score'] = df['virality_score'].replace([np.inf,-np.inf],np.nan).fillna(0)
top5 = df.nlargest(5, 'virality_score')
if 'caption' in top5.columns:
    t5 = top5[['caption','reach','predicted_reach','virality_score']].copy()
    t5['reach']           = t5['reach'].apply(fmt)
    t5['predicted_reach'] = t5['predicted_reach'].apply(fmt)
    t5['virality_score']  = t5['virality_score'].apply(lambda x: f"{x:.2f}x")
    t5 = t5.rename(columns={
        'caption':'Caption','reach':'Reach',
        'predicted_reach':'Predicted Reach','virality_score':'Virality Score'
    })
    st.dataframe(t5, use_container_width=True)

# â”€â”€ Strategic Takeaways â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("ğŸš€ Strategic Takeaways")
st.markdown(f"""
1. **Shares** drive reach most strongly overall (r={corr_overall['shares']:.2f}).  
2. **Correlations vary by category**â€”see chart above to tailor your strategy.  
3. **If all engagement levers are optimized yet reach lags**, revisit your hook/creative.
""")

# â”€â”€ Download & Predict & Diagnose â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.subheader("â¬‡ï¸ Download Full Data")
st.download_button("Download CSV", df.to_csv(index=False).encode('utf-8'),
                   "reels_with_predictions.csv", "text/csv")

st.subheader("ğŸ¯ Predict & Diagnose for a New Reel")
with st.form("pd_form"):
    s  = st.number_input("Shares",    min_value=0, value=0)
    sv = st.number_input("Saves",     min_value=0, value=0)
    c  = st.number_input("Comments",  min_value=0, value=0)
    l  = st.number_input("Likes",     min_value=0, value=0)
    ar = st.number_input("Actual Reach", min_value=0, value=0)
    go = st.form_submit_button("Diagnose")

if go:
    inp = pd.DataFrame([{'shares':s,'saved':sv,'comments':c,'likes':l}])
    pred = model.predict(inp)[0]
    perf = categorize(ar, pred)
    st.success(f"ğŸ“¢ Predicted Reach: {fmt(pred)}")
    st.info(f"ğŸ” Actual Reach: {fmt(ar)}")
    st.info(f"ğŸ¯ Category: **{perf}**")

    # Show per-category correlation table
    st.markdown("**ğŸ“ˆ Engagement Correlations by Category:**")
    st.table(corr_by_cat)

    # Recommend next metric to optimize
    if perf in ['Poor','Average','Good','Excellent']:
        next_bucket = {'Poor':'Average','Average':'Good','Good':'Excellent','Excellent':'Viral'}[perf]
        best_metric = corr_by_cat[next_bucket].idxmax()
        best_val    = corr_by_cat[next_bucket].max()
        st.markdown(f"ğŸ”œ To move from **{perf}** â†’ **{next_bucket}**, focus on **{best_metric.capitalize()}** (r={best_val:.2f}).")
    else:
        st.markdown("âœ… Youâ€™re already in the Viral categoryâ€”keep up the great work!")
